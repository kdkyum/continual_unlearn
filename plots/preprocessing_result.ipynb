{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6c3fd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set(font_scale=1.2)\n",
    "plt.rcParams['figure.figsize'] = (14, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5121a905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found methods: ['FT_continual_unlearn', 'retrain_continual_unlearn', 'NG_continual_unlearn', 'synaptag_continual_unlearn', 'GA_continual_unlearn', 'RL_continual_unlearn']\n",
      "Method FT_continual_unlearn has datasets: ['cifar10', 'cifar100']\n",
      "Method retrain_continual_unlearn has datasets: ['cifar10', 'cifar100']\n",
      "Method NG_continual_unlearn has datasets: ['cifar10', 'cifar100']\n",
      "Method synaptag_continual_unlearn has datasets: ['cifar10', 'cifar100']\n",
      "Method GA_continual_unlearn has datasets: ['cifar10', 'cifar100']\n",
      "Method RL_continual_unlearn has datasets: ['cifar10', 'cifar100']\n"
     ]
    }
   ],
   "source": [
    "# Base directory for checkpoints\n",
    "base_dir = \"/u/kdkyum/ptmp_link/workdir/continual_unlearn/checkpoints\"\n",
    "\n",
    "# Function to find all available methods with continual_unlearn suffix\n",
    "def find_methods():\n",
    "    methods = []\n",
    "    if os.path.exists(base_dir):\n",
    "        for item in os.listdir(base_dir):\n",
    "            if item.endswith(\"_continual_unlearn\") and os.path.isdir(os.path.join(base_dir, item)):\n",
    "                methods.append(item)\n",
    "    return methods\n",
    "\n",
    "# Get all methods\n",
    "methods = find_methods()\n",
    "print(f\"Found methods: {methods}\")\n",
    "\n",
    "# Identify available datasets for each method\n",
    "datasets = {}\n",
    "for method in methods:\n",
    "    method_dir = os.path.join(base_dir, method)\n",
    "    datasets[method] = [d for d in os.listdir(method_dir) if os.path.isdir(os.path.join(method_dir, d))]\n",
    "    print(f\"Method {method} has datasets: {datasets[method]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e1e4806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_evaluation_results(method, dataset):\n",
    "    \"\"\"Load evaluation results for a specific method and dataset\"\"\"\n",
    "    results = []\n",
    "    method_dir = os.path.join(base_dir, method, dataset)\n",
    "    \n",
    "    if not os.path.exists(method_dir):\n",
    "        print(f\"Directory not found: {method_dir}\")\n",
    "        return results\n",
    "    \n",
    "    # Get all forget stages\n",
    "    forget_stages = []\n",
    "    for stage_dir in os.listdir(method_dir):\n",
    "        stage_path = os.path.join(method_dir, stage_dir)\n",
    "        if os.path.isdir(stage_path):\n",
    "            try:\n",
    "                # Handle both underscore and hyphen formats (e.g., '0_1' or '0-1')\n",
    "                if '-' in stage_dir:\n",
    "                    begin, end = map(int, stage_dir.split('-'))\n",
    "                elif '_' in stage_dir:\n",
    "                    begin, end = map(int, stage_dir.split('_'))\n",
    "                else:\n",
    "                    # Skip directories that don't follow either pattern\n",
    "                    raise ValueError(f\"Directory name format not recognized: {stage_dir}\")\n",
    "                    \n",
    "                forget_stages.append((begin, end, stage_dir, stage_path))\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping directory with invalid format: {stage_dir} - {str(e)}\")\n",
    "    \n",
    "    # Sort by end class for proper ordering\n",
    "    forget_stages.sort(key=lambda x: x[1])\n",
    "    \n",
    "    # Load results for each stage\n",
    "    for begin, end, stage_dir, stage_path in forget_stages:\n",
    "        eval_file = os.path.join(stage_path, 'evaluation_results.json')\n",
    "        if os.path.exists(eval_file):\n",
    "            try:\n",
    "                with open(eval_file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    results.append({\n",
    "                        'method': method,\n",
    "                        'dataset': dataset,\n",
    "                        'forget_class_begin': begin,\n",
    "                        'forget_class_end': end,\n",
    "                        'data': data,\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {eval_file}: {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def extract_metrics(results):\n",
    "    \"\"\"Extract key metrics from loaded results into a structured DataFrame\"\"\"\n",
    "    metrics_data = []\n",
    "    \n",
    "    for result in results:\n",
    "        method = result['method']\n",
    "        method_display = method.replace('_continual_unlearn', '')\n",
    "        dataset = result['dataset']\n",
    "        forget_begin = result['forget_class_begin']\n",
    "        forget_end = result['forget_class_end']\n",
    "        data = result['data']\n",
    "        \n",
    "        # Extract common metrics\n",
    "        metrics = {\n",
    "            'method': method_display,\n",
    "            'dataset': dataset,\n",
    "            'forget_class_begin': forget_begin,\n",
    "            'forget_class_end': forget_end,\n",
    "            'classes_forgotten': forget_end - forget_begin,\n",
    "            'unlearning_time': data.get('unlearning_time', None)\n",
    "        }\n",
    "        \n",
    "        # Extract accuracy metrics\n",
    "        if 'accuracy' in data:\n",
    "            if isinstance(data['accuracy'], dict):\n",
    "                for key, value in data['accuracy'].items():\n",
    "                    metrics[f'accuracy_{key}'] = value\n",
    "            else:\n",
    "                metrics['accuracy'] = data['accuracy']\n",
    "\n",
    "        for x in data[\"class_wise_accuracy\"]:\n",
    "            metrics[f'accuracy_class_{x[\"class\"]}'] = x.get('accuracy', None)\n",
    "        \n",
    "        # Extract MIA metrics\n",
    "        if 'SVC_MIA_forget_efficacy' in data:\n",
    "            for key, value in data['SVC_MIA_forget_efficacy'].items():\n",
    "                metrics[f'mia_forget_{key}'] = value\n",
    "                \n",
    "        metrics_data.append(metrics)\n",
    "    \n",
    "    return pd.DataFrame(metrics_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdfaf1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping directory with invalid format: masks - Directory name format not recognized: masks\n",
      "Loaded 40 evaluation results\n",
      "Methods: ['FT' 'retrain' 'NG' 'synaptag' 'GA']\n",
      "Datasets: ['cifar10']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>dataset</th>\n",
       "      <th>forget_class_begin</th>\n",
       "      <th>forget_class_end</th>\n",
       "      <th>classes_forgotten</th>\n",
       "      <th>unlearning_time</th>\n",
       "      <th>accuracy_retain</th>\n",
       "      <th>accuracy_forget</th>\n",
       "      <th>accuracy_val</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>...</th>\n",
       "      <th>accuracy_class_5</th>\n",
       "      <th>accuracy_class_6</th>\n",
       "      <th>accuracy_class_7</th>\n",
       "      <th>accuracy_class_8</th>\n",
       "      <th>accuracy_class_9</th>\n",
       "      <th>mia_forget_correctness</th>\n",
       "      <th>mia_forget_confidence</th>\n",
       "      <th>mia_forget_entropy</th>\n",
       "      <th>mia_forget_m_entropy</th>\n",
       "      <th>mia_forget_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FT</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>143.505831</td>\n",
       "      <td>98.012346</td>\n",
       "      <td>1.844444</td>\n",
       "      <td>87.02</td>\n",
       "      <td>83.40</td>\n",
       "      <td>...</td>\n",
       "      <td>83.500000</td>\n",
       "      <td>94.500000</td>\n",
       "      <td>94.699997</td>\n",
       "      <td>97.900002</td>\n",
       "      <td>94.500000</td>\n",
       "      <td>0.981556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.811333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FT</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>127.511504</td>\n",
       "      <td>98.694444</td>\n",
       "      <td>14.933333</td>\n",
       "      <td>79.92</td>\n",
       "      <td>75.08</td>\n",
       "      <td>...</td>\n",
       "      <td>85.699997</td>\n",
       "      <td>94.599998</td>\n",
       "      <td>93.599998</td>\n",
       "      <td>98.400002</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>0.850667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.876222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FT</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>115.667961</td>\n",
       "      <td>98.304762</td>\n",
       "      <td>2.044444</td>\n",
       "      <td>68.44</td>\n",
       "      <td>65.20</td>\n",
       "      <td>...</td>\n",
       "      <td>94.300003</td>\n",
       "      <td>94.800003</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>97.300003</td>\n",
       "      <td>0.979556</td>\n",
       "      <td>0.999778</td>\n",
       "      <td>0.915778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.702667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FT</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>99.204968</td>\n",
       "      <td>99.785185</td>\n",
       "      <td>10.155556</td>\n",
       "      <td>60.56</td>\n",
       "      <td>59.28</td>\n",
       "      <td>...</td>\n",
       "      <td>94.400002</td>\n",
       "      <td>98.599998</td>\n",
       "      <td>97.099998</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>98.400002</td>\n",
       "      <td>0.898444</td>\n",
       "      <td>0.996444</td>\n",
       "      <td>0.807333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.562889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FT</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>84.374024</td>\n",
       "      <td>99.657778</td>\n",
       "      <td>27.600000</td>\n",
       "      <td>52.14</td>\n",
       "      <td>51.31</td>\n",
       "      <td>...</td>\n",
       "      <td>98.699997</td>\n",
       "      <td>97.300003</td>\n",
       "      <td>94.599998</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>98.800003</td>\n",
       "      <td>0.724000</td>\n",
       "      <td>0.985333</td>\n",
       "      <td>0.905111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.945556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  method  dataset  forget_class_begin  forget_class_end  classes_forgotten  \\\n",
       "0     FT  cifar10                   0                 0                  0   \n",
       "1     FT  cifar10                   0                 1                  1   \n",
       "2     FT  cifar10                   0                 2                  2   \n",
       "3     FT  cifar10                   0                 3                  3   \n",
       "4     FT  cifar10                   0                 4                  4   \n",
       "\n",
       "   unlearning_time  accuracy_retain  accuracy_forget  accuracy_val  \\\n",
       "0       143.505831        98.012346         1.844444         87.02   \n",
       "1       127.511504        98.694444        14.933333         79.92   \n",
       "2       115.667961        98.304762         2.044444         68.44   \n",
       "3        99.204968        99.785185        10.155556         60.56   \n",
       "4        84.374024        99.657778        27.600000         52.14   \n",
       "\n",
       "   accuracy_test  ...  accuracy_class_5  accuracy_class_6  accuracy_class_7  \\\n",
       "0          83.40  ...         83.500000         94.500000         94.699997   \n",
       "1          75.08  ...         85.699997         94.599998         93.599998   \n",
       "2          65.20  ...         94.300003         94.800003         94.000000   \n",
       "3          59.28  ...         94.400002         98.599998         97.099998   \n",
       "4          51.31  ...         98.699997         97.300003         94.599998   \n",
       "\n",
       "   accuracy_class_8  accuracy_class_9  mia_forget_correctness  \\\n",
       "0         97.900002         94.500000                0.981556   \n",
       "1         98.400002         96.500000                0.850667   \n",
       "2         98.000000         97.300003                0.979556   \n",
       "3         98.500000         98.400002                0.898444   \n",
       "4         97.000000         98.800003                0.724000   \n",
       "\n",
       "   mia_forget_confidence  mia_forget_entropy  mia_forget_m_entropy  \\\n",
       "0               1.000000            0.811333                   1.0   \n",
       "1               1.000000            0.876222                   1.0   \n",
       "2               0.999778            0.915778                   1.0   \n",
       "3               0.996444            0.807333                   1.0   \n",
       "4               0.985333            0.905111                   1.0   \n",
       "\n",
       "   mia_forget_prob  \n",
       "0         0.941111  \n",
       "1         0.998222  \n",
       "2         0.702667  \n",
       "3         0.562889  \n",
       "4         0.945556  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all results\n",
    "all_results = []\n",
    "for method in methods:\n",
    "    # for dataset in datasets[method]:\n",
    "    method_results = load_evaluation_results(method, \"cifar10\")\n",
    "    all_results.extend(method_results)\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "df = extract_metrics(all_results)\n",
    "\n",
    "# Show basic stats\n",
    "print(f\"Loaded {len(df)} evaluation results\")\n",
    "print(f\"Methods: {df['method'].unique()}\")\n",
    "print(f\"Datasets: {df['dataset'].unique()}\")\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5c274d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"eval_results_for_cifar10.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5777f783",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
