{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6c3fd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set(font_scale=1.2)\n",
    "plt.rcParams['figure.figsize'] = (14, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5121a905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found methods: ['FT_continual_unlearn', 'synaptag_GA_continual_unlearn', 'retrain_continual_unlearn', 'NG_continual_unlearn', 'synaptag_continual_unlearn', 'synaptag_RL_continual_unlearn', 'GA_continual_unlearn', 'RL_continual_unlearn']\n",
      "Method FT_continual_unlearn has datasets: ['cifar10', 'cifar100']\n",
      "Method synaptag_GA_continual_unlearn has datasets: ['cifar10', 'cifar100']\n",
      "Method retrain_continual_unlearn has datasets: ['cifar10', 'cifar100']\n",
      "Method NG_continual_unlearn has datasets: ['cifar10', 'cifar100']\n",
      "Method synaptag_continual_unlearn has datasets: ['cifar10', 'cifar100']\n",
      "Method synaptag_RL_continual_unlearn has datasets: ['cifar10', 'cifar100']\n",
      "Method GA_continual_unlearn has datasets: ['cifar10', 'cifar100']\n",
      "Method RL_continual_unlearn has datasets: ['cifar10', 'cifar100']\n"
     ]
    }
   ],
   "source": [
    "# Base directory for checkpoints\n",
    "base_dir = \"/u/kdkyum/ptmp_link/workdir/continual_unlearn/checkpoints\"\n",
    "\n",
    "# Function to find all available methods with continual_unlearn suffix\n",
    "def find_methods():\n",
    "    methods = []\n",
    "    if os.path.exists(base_dir):\n",
    "        for item in os.listdir(base_dir):\n",
    "            if item.endswith(\"_continual_unlearn\") and os.path.isdir(os.path.join(base_dir, item)):\n",
    "                methods.append(item)\n",
    "    return methods\n",
    "\n",
    "# Get all methods\n",
    "methods = find_methods()\n",
    "print(f\"Found methods: {methods}\")\n",
    "\n",
    "# Identify available datasets for each method\n",
    "datasets = {}\n",
    "for method in methods:\n",
    "    method_dir = os.path.join(base_dir, method)\n",
    "    datasets[method] = [d for d in os.listdir(method_dir) if os.path.isdir(os.path.join(method_dir, d))]\n",
    "    print(f\"Method {method} has datasets: {datasets[method]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e1e4806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_evaluation_results(method, dataset):\n",
    "    \"\"\"Load evaluation results for a specific method and dataset\"\"\"\n",
    "    results = []\n",
    "    method_dir = os.path.join(base_dir, method, dataset)\n",
    "    \n",
    "    if not os.path.exists(method_dir):\n",
    "        print(f\"Directory not found: {method_dir}\")\n",
    "        return results\n",
    "    \n",
    "    # Get all forget stages\n",
    "    forget_stages = []\n",
    "    for stage_dir in os.listdir(method_dir):\n",
    "        stage_path = os.path.join(method_dir, stage_dir)\n",
    "        if os.path.isdir(stage_path):\n",
    "            try:\n",
    "                # Handle both underscore and hyphen formats (e.g., '0_1' or '0-1')\n",
    "                if '-' in stage_dir:\n",
    "                    begin, end = map(int, stage_dir.split('-'))\n",
    "                elif '_' in stage_dir:\n",
    "                    begin, end = map(int, stage_dir.split('_'))\n",
    "                else:\n",
    "                    # Skip directories that don't follow either pattern\n",
    "                    raise ValueError(f\"Directory name format not recognized: {stage_dir}\")\n",
    "                    \n",
    "                forget_stages.append((begin, end, stage_dir, stage_path))\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping directory with invalid format: {stage_dir} - {str(e)}\")\n",
    "    \n",
    "    # Sort by end class for proper ordering\n",
    "    forget_stages.sort(key=lambda x: x[1])\n",
    "    \n",
    "    # Load results for each stage\n",
    "    for begin, end, stage_dir, stage_path in forget_stages:\n",
    "        eval_file = os.path.join(stage_path, 'evaluation_results.json')\n",
    "        if os.path.exists(eval_file):\n",
    "            try:\n",
    "                with open(eval_file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    results.append({\n",
    "                        'method': method,\n",
    "                        'dataset': dataset,\n",
    "                        'forget_class_begin': begin,\n",
    "                        'forget_class_end': end,\n",
    "                        'data': data,\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {eval_file}: {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def extract_metrics(results):\n",
    "    \"\"\"Extract key metrics from loaded results into a structured DataFrame\"\"\"\n",
    "    metrics_data = []\n",
    "    \n",
    "    for result in results:\n",
    "        method = result['method']\n",
    "        method_display = method.replace('_continual_unlearn', '')\n",
    "        dataset = result['dataset']\n",
    "        forget_begin = result['forget_class_begin']\n",
    "        forget_end = result['forget_class_end']\n",
    "        data = result['data']\n",
    "        \n",
    "        # Extract common metrics\n",
    "        metrics = {\n",
    "            'method': method_display,\n",
    "            'dataset': dataset,\n",
    "            'forget_class_begin': forget_begin,\n",
    "            'forget_class_end': forget_end,\n",
    "            'classes_forgotten': forget_end - forget_begin,\n",
    "            'unlearning_time': data.get('unlearning_time', None)\n",
    "        }\n",
    "        \n",
    "        # Extract accuracy metrics\n",
    "        if 'accuracy' in data:\n",
    "            if isinstance(data['accuracy'], dict):\n",
    "                for key, value in data['accuracy'].items():\n",
    "                    metrics[f'accuracy_{key}'] = value\n",
    "            else:\n",
    "                metrics['accuracy'] = data['accuracy']\n",
    "\n",
    "        for x in data[\"class_wise_accuracy\"]:\n",
    "            metrics[f'accuracy_class_{x[\"class\"]}'] = x.get('accuracy', None)\n",
    "        \n",
    "        # Extract MIA metrics\n",
    "        if 'SVC_MIA_forget_efficacy' in data:\n",
    "            for key, value in data['SVC_MIA_forget_efficacy'].items():\n",
    "                metrics[f'mia_forget_{key}'] = value\n",
    "                \n",
    "        metrics_data.append(metrics)\n",
    "    \n",
    "    return pd.DataFrame(metrics_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfaf1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping directory with invalid format: masks - Directory name format not recognized: masks\n",
      "Loaded 144 evaluation results\n",
      "Methods: ['FT' 'synaptag_GA' 'retrain' 'NG' 'synaptag' 'synaptag_RL' 'GA' 'RL']\n",
      "Datasets: ['cifar100']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>dataset</th>\n",
       "      <th>forget_class_begin</th>\n",
       "      <th>forget_class_end</th>\n",
       "      <th>classes_forgotten</th>\n",
       "      <th>unlearning_time</th>\n",
       "      <th>accuracy_retain</th>\n",
       "      <th>accuracy_forget</th>\n",
       "      <th>accuracy_val</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>...</th>\n",
       "      <th>accuracy_class_95</th>\n",
       "      <th>accuracy_class_96</th>\n",
       "      <th>accuracy_class_97</th>\n",
       "      <th>accuracy_class_98</th>\n",
       "      <th>accuracy_class_99</th>\n",
       "      <th>mia_forget_correctness</th>\n",
       "      <th>mia_forget_confidence</th>\n",
       "      <th>mia_forget_entropy</th>\n",
       "      <th>mia_forget_m_entropy</th>\n",
       "      <th>mia_forget_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FT</td>\n",
       "      <td>cifar100</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>151.605011</td>\n",
       "      <td>97.417544</td>\n",
       "      <td>2.533333</td>\n",
       "      <td>88.70</td>\n",
       "      <td>69.43</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.999111</td>\n",
       "      <td>0.831556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.855111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FT</td>\n",
       "      <td>cifar100</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>143.148822</td>\n",
       "      <td>97.338272</td>\n",
       "      <td>13.422222</td>\n",
       "      <td>85.24</td>\n",
       "      <td>64.68</td>\n",
       "      <td>...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.865778</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FT</td>\n",
       "      <td>cifar100</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>133.531575</td>\n",
       "      <td>98.392157</td>\n",
       "      <td>25.777778</td>\n",
       "      <td>82.74</td>\n",
       "      <td>63.67</td>\n",
       "      <td>...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.742222</td>\n",
       "      <td>0.972000</td>\n",
       "      <td>0.864889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.907111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FT</td>\n",
       "      <td>cifar100</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>126.807690</td>\n",
       "      <td>96.138889</td>\n",
       "      <td>12.311111</td>\n",
       "      <td>75.26</td>\n",
       "      <td>57.50</td>\n",
       "      <td>...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.876889</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>0.908444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.847111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FT</td>\n",
       "      <td>cifar100</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>121.599784</td>\n",
       "      <td>99.194074</td>\n",
       "      <td>32.977778</td>\n",
       "      <td>74.18</td>\n",
       "      <td>57.75</td>\n",
       "      <td>...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.670222</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.948889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.876444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  method   dataset  forget_class_begin  forget_class_end  classes_forgotten  \\\n",
       "0     FT  cifar100                   0                 4                  4   \n",
       "1     FT  cifar100                   0                 9                  9   \n",
       "2     FT  cifar100                   0                14                 14   \n",
       "3     FT  cifar100                   0                19                 19   \n",
       "4     FT  cifar100                   0                24                 24   \n",
       "\n",
       "   unlearning_time  accuracy_retain  accuracy_forget  accuracy_val  \\\n",
       "0       151.605011        97.417544         2.533333         88.70   \n",
       "1       143.148822        97.338272        13.422222         85.24   \n",
       "2       133.531575        98.392157        25.777778         82.74   \n",
       "3       126.807690        96.138889        12.311111         75.26   \n",
       "4       121.599784        99.194074        32.977778         74.18   \n",
       "\n",
       "   accuracy_test  ...  accuracy_class_95  accuracy_class_96  \\\n",
       "0          69.43  ...               54.0               61.0   \n",
       "1          64.68  ...               73.0               60.0   \n",
       "2          63.67  ...               55.0               72.0   \n",
       "3          57.50  ...               81.0               61.0   \n",
       "4          57.75  ...               69.0               51.0   \n",
       "\n",
       "   accuracy_class_97  accuracy_class_98  accuracy_class_99  \\\n",
       "0               74.0               59.0               66.0   \n",
       "1               72.0               78.0               63.0   \n",
       "2               70.0               75.0               72.0   \n",
       "3               71.0               65.0               70.0   \n",
       "4               84.0               73.0               64.0   \n",
       "\n",
       "   mia_forget_correctness  mia_forget_confidence  mia_forget_entropy  \\\n",
       "0                0.974667               0.999111            0.831556   \n",
       "1                0.865778               0.988889            0.848000   \n",
       "2                0.742222               0.972000            0.864889   \n",
       "3                0.876889               0.981333            0.908444   \n",
       "4                0.670222               0.989333            0.948889   \n",
       "\n",
       "   mia_forget_m_entropy  mia_forget_prob  \n",
       "0                   1.0         0.855111  \n",
       "1                   1.0         0.954222  \n",
       "2                   1.0         0.907111  \n",
       "3                   1.0         0.847111  \n",
       "4                   1.0         0.876444  \n",
       "\n",
       "[5 rows x 115 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all results\n",
    "all_results = []\n",
    "for method in methods:\n",
    "    # for dataset in datasets[method]:\n",
    "    method_results = load_evaluation_results(method, \"cifar10\")\n",
    "    all_results.extend(method_results)\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "df = extract_metrics(all_results)\n",
    "\n",
    "# Show basic stats\n",
    "print(f\"Loaded {len(df)} evaluation results\")\n",
    "print(f\"Methods: {df['method'].unique()}\")\n",
    "print(f\"Datasets: {df['dataset'].unique()}\")\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c274d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"eval_results_for_cifar10.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5777f783",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
